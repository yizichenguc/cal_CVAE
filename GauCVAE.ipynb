{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac62a8ce-ca41-402e-98c6-c99c77275e03",
   "metadata": {},
   "source": [
    "DATA_PREP.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09abd690-b9cb-490b-892c-ea2572885bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PES0841/yizicheng/.conda/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a0a637-836b-4bbf-aaac-dedc99d5c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class THICKNESS(Dataset):\n",
    "    def __init__(self, input_nm = 'x', output_nm = 'y', mode = 'train', transform=None):\n",
    "        if mode == 'train':\n",
    "            root_input = input_nm + '_train.npy'\n",
    "            root_output = output_nm + '_train.npy'\n",
    "        elif mode == 'val':\n",
    "            root_input = input_nm + '_val.npy'\n",
    "            root_output = output_nm + '_val.npy'\n",
    "        else:\n",
    "            root_input = input_nm + '_test.npy'\n",
    "            root_output = output_nm + '_test.npy'\n",
    "            \n",
    "        self.original_input = np.load(root_input)\n",
    "        self.original_output = np.load(root_output)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.original_input)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inp = self.original_input[item]\n",
    "        out = self.original_output[item]\n",
    "        sample = {\"input\": inp, \"output\": out}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        sample[\"input\"] = torch.as_tensor(sample[\"input\"], dtype=torch.float32)\n",
    "        sample[\"output\"] = torch.as_tensor(sample[\"output\"], dtype=torch.float32)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "def get_data(batch_size):\n",
    "    transforms = ToTensor()\n",
    "    \n",
    "    datasets, dataloaders, dataset_sizes = {}, {}, {}\n",
    "    for mode in [\"train\", \"val\", \"test\"]:\n",
    "        datasets[mode] = THICKNESS(mode = mode, transform = transforms)\n",
    "        dataloaders[mode] = DataLoader(\n",
    "            datasets[mode],\n",
    "            batch_size=batch_size,\n",
    "#             shuffle= True,\n",
    "            shuffle= mode == \"train\",\n",
    "            num_workers=0,\n",
    "        )\n",
    "        dataset_sizes[mode] = len(datasets[mode])\n",
    "\n",
    "    return datasets, dataloaders, dataset_sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a112da-65f6-4c02-9dc4-4b9d7ed4352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, dataloaders, dataset_sizes = get_data(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e4d45-f93d-41c9-9bff-d08a7c3f9822",
   "metadata": {},
   "source": [
    "BASELINE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d37496-cc89-4b99-8d41-2786a4f3e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "        \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d583d4c2-6548-418a-a5d6-6d15cd2b5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import pyro\n",
    "# import pyro.distributions as dist\n",
    "# from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "# x = torch.ones(30,1,171,171)\n",
    "\n",
    "# x = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(30, 30))(x)\n",
    "\n",
    "# x = nn.MaxPool2d(kernel_size=(5, 5), stride=(5, 5))(x)\n",
    "\n",
    "# x = nn.MaxPool2d(kernel_size=(30, 30), stride=(30, 30))(x)\n",
    "\n",
    "# y = torch.flatten(x, 1)\n",
    "\n",
    "# x.shape\n",
    "\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4eecb85-7d1b-453d-9084-ec8426645f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(30, 30))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(5, 5), stride=(5, 5))\n",
    "        self.fc1 = nn.Linear(7840, 100)\n",
    "        self.fc2 = nn.Linear(100, 4)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 171, 171)\n",
    "        x = x.unsqueeze(1)\n",
    "        hidden = self.leakyrelu(self.conv(x))\n",
    "        hidden = self.maxpool(hidden)\n",
    "        \n",
    "        hidden = torch.flatten(hidden, 1)\n",
    "        hidden = self.leakyrelu(self.fc1(hidden))\n",
    "        \n",
    "        y = self.fc2(hidden)\n",
    "        return y\n",
    "\n",
    "\n",
    "class MSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        target = target.view(input.shape)\n",
    "        loss = F.mse_loss(input, target, reduction=\"sum\")\n",
    "        return loss\n",
    "\n",
    "\n",
    "def train(\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    early_stop_patience,\n",
    "    model_path,\n",
    "):\n",
    "\n",
    "    # Train baseline\n",
    "    baseline_net = BaselineNet()\n",
    "    baseline_net.to(device)\n",
    "    optimizer = torch.optim.Adam(baseline_net.parameters(), lr=learning_rate)\n",
    "    criterion = MSELoss()\n",
    "    best_loss = np.inf\n",
    "    early_stop_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                baseline_net.train()\n",
    "            else:\n",
    "                baseline_net.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            num_preds = 0\n",
    "\n",
    "            bar = tqdm(\n",
    "                dataloaders[phase], desc=\"NN Epoch {} {}\".format(epoch, phase).ljust(20)\n",
    "            )\n",
    "            for i, batch in enumerate(bar):\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                outputs = batch[\"output\"].to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    preds = baseline_net(inputs)\n",
    "                    loss = criterion(preds, outputs) / inputs.size(0)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                num_preds += 1\n",
    "                if i % 10 == 0:\n",
    "                    bar.set_postfix(\n",
    "                        loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                        early_stop_count=early_stop_count,\n",
    "                    )\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # deep copy the model\n",
    "            if phase == \"val\":\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(baseline_net.state_dict())\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    baseline_net.load_state_dict(best_model_wts)\n",
    "    baseline_net.eval()\n",
    "\n",
    "    # Save model weights\n",
    "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(baseline_net.state_dict(), model_path)\n",
    "\n",
    "    return baseline_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e989ddd5-2111-4095-9230-54703c881fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Epoch 0 train    : 100%|██████████| 176/176 [00:04<00:00, 39.17it/s, early_stop_count=0, loss=0.32]\n",
      "NN Epoch 0 val      : 100%|██████████| 59/59 [00:00<00:00, 133.18it/s, early_stop_count=0, loss=0.21]\n",
      "NN Epoch 1 train    : 100%|██████████| 176/176 [00:03<00:00, 58.58it/s, early_stop_count=0, loss=0.19]\n",
      "NN Epoch 1 val      : 100%|██████████| 59/59 [00:00<00:00, 133.60it/s, early_stop_count=0, loss=0.16]\n",
      "NN Epoch 2 train    : 100%|██████████| 176/176 [00:03<00:00, 58.58it/s, early_stop_count=0, loss=0.16]\n",
      "NN Epoch 2 val      : 100%|██████████| 59/59 [00:00<00:00, 133.70it/s, early_stop_count=0, loss=0.17]\n",
      "NN Epoch 3 train    : 100%|██████████| 176/176 [00:03<00:00, 58.47it/s, early_stop_count=1, loss=0.14]\n",
      "NN Epoch 3 val      : 100%|██████████| 59/59 [00:00<00:00, 134.63it/s, early_stop_count=1, loss=0.14]\n",
      "NN Epoch 4 train    : 100%|██████████| 176/176 [00:02<00:00, 58.98it/s, early_stop_count=0, loss=0.13]\n",
      "NN Epoch 4 val      : 100%|██████████| 59/59 [00:00<00:00, 129.45it/s, early_stop_count=0, loss=0.12]\n",
      "NN Epoch 5 train    : 100%|██████████| 176/176 [00:02<00:00, 58.90it/s, early_stop_count=0, loss=0.12]\n",
      "NN Epoch 5 val      : 100%|██████████| 59/59 [00:00<00:00, 135.77it/s, early_stop_count=0, loss=0.12]\n",
      "NN Epoch 6 train    : 100%|██████████| 176/176 [00:02<00:00, 58.82it/s, early_stop_count=0, loss=0.11]\n",
      "NN Epoch 6 val      : 100%|██████████| 59/59 [00:00<00:00, 134.65it/s, early_stop_count=0, loss=0.11]\n",
      "NN Epoch 7 train    : 100%|██████████| 176/176 [00:02<00:00, 58.70it/s, early_stop_count=0, loss=0.10]\n",
      "NN Epoch 7 val      : 100%|██████████| 59/59 [00:00<00:00, 135.49it/s, early_stop_count=0, loss=0.11]\n",
      "NN Epoch 8 train    : 100%|██████████| 176/176 [00:02<00:00, 58.77it/s, early_stop_count=0, loss=0.09]\n",
      "NN Epoch 8 val      : 100%|██████████| 59/59 [00:00<00:00, 135.47it/s, early_stop_count=0, loss=0.10]\n",
      "NN Epoch 9 train    : 100%|██████████| 176/176 [00:02<00:00, 58.83it/s, early_stop_count=0, loss=0.09]\n",
      "NN Epoch 9 val      : 100%|██████████| 59/59 [00:00<00:00, 135.73it/s, early_stop_count=0, loss=0.10]\n",
      "NN Epoch 10 train   : 100%|██████████| 176/176 [00:02<00:00, 58.93it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 10 val     : 100%|██████████| 59/59 [00:00<00:00, 135.63it/s, early_stop_count=0, loss=0.10]\n",
      "NN Epoch 11 train   : 100%|██████████| 176/176 [00:02<00:00, 58.89it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 11 val     : 100%|██████████| 59/59 [00:00<00:00, 135.77it/s, early_stop_count=0, loss=0.09]\n",
      "NN Epoch 12 train   : 100%|██████████| 176/176 [00:03<00:00, 58.11it/s, early_stop_count=0, loss=0.07]\n",
      "NN Epoch 12 val     : 100%|██████████| 59/59 [00:00<00:00, 133.94it/s, early_stop_count=0, loss=0.09]\n",
      "NN Epoch 13 train   : 100%|██████████| 176/176 [00:03<00:00, 58.54it/s, early_stop_count=1, loss=0.07]\n",
      "NN Epoch 13 val     : 100%|██████████| 59/59 [00:00<00:00, 133.62it/s, early_stop_count=1, loss=0.09]\n",
      "NN Epoch 14 train   : 100%|██████████| 176/176 [00:03<00:00, 58.52it/s, early_stop_count=0, loss=0.07]\n",
      "NN Epoch 14 val     : 100%|██████████| 59/59 [00:00<00:00, 132.40it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 15 train   : 100%|██████████| 176/176 [00:03<00:00, 58.66it/s, early_stop_count=0, loss=0.06]\n",
      "NN Epoch 15 val     : 100%|██████████| 59/59 [00:00<00:00, 133.71it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 16 train   : 100%|██████████| 176/176 [00:03<00:00, 58.62it/s, early_stop_count=0, loss=0.06]\n",
      "NN Epoch 16 val     : 100%|██████████| 59/59 [00:00<00:00, 134.01it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 17 train   : 100%|██████████| 176/176 [00:03<00:00, 58.53it/s, early_stop_count=1, loss=0.06]\n",
      "NN Epoch 17 val     : 100%|██████████| 59/59 [00:00<00:00, 133.69it/s, early_stop_count=1, loss=0.08]\n",
      "NN Epoch 18 train   : 100%|██████████| 176/176 [00:03<00:00, 58.45it/s, early_stop_count=2, loss=0.06]\n",
      "NN Epoch 18 val     : 100%|██████████| 59/59 [00:00<00:00, 133.54it/s, early_stop_count=2, loss=0.08]\n",
      "NN Epoch 19 train   : 100%|██████████| 176/176 [00:03<00:00, 58.45it/s, early_stop_count=3, loss=0.06]\n",
      "NN Epoch 19 val     : 100%|██████████| 59/59 [00:00<00:00, 134.10it/s, early_stop_count=3, loss=0.08]\n",
      "NN Epoch 20 train   : 100%|██████████| 176/176 [00:03<00:00, 58.65it/s, early_stop_count=0, loss=0.05]\n",
      "NN Epoch 20 val     : 100%|██████████| 59/59 [00:00<00:00, 132.95it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 21 train   : 100%|██████████| 176/176 [00:03<00:00, 58.63it/s, early_stop_count=0, loss=0.06]\n",
      "NN Epoch 21 val     : 100%|██████████| 59/59 [00:00<00:00, 133.91it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 22 train   : 100%|██████████| 176/176 [00:02<00:00, 58.91it/s, early_stop_count=1, loss=0.05]\n",
      "NN Epoch 22 val     : 100%|██████████| 59/59 [00:00<00:00, 134.34it/s, early_stop_count=1, loss=0.08]\n",
      "NN Epoch 23 train   : 100%|██████████| 176/176 [00:03<00:00, 57.99it/s, early_stop_count=0, loss=0.05]\n",
      "NN Epoch 23 val     : 100%|██████████| 59/59 [00:00<00:00, 136.44it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 24 train   : 100%|██████████| 176/176 [00:02<00:00, 59.23it/s, early_stop_count=1, loss=0.05]\n",
      "NN Epoch 24 val     : 100%|██████████| 59/59 [00:00<00:00, 136.89it/s, early_stop_count=1, loss=0.08]\n",
      "NN Epoch 25 train   : 100%|██████████| 176/176 [00:02<00:00, 59.16it/s, early_stop_count=0, loss=0.05]\n",
      "NN Epoch 25 val     : 100%|██████████| 59/59 [00:00<00:00, 137.02it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 26 train   : 100%|██████████| 176/176 [00:02<00:00, 59.15it/s, early_stop_count=1, loss=0.05]\n",
      "NN Epoch 26 val     : 100%|██████████| 59/59 [00:00<00:00, 136.90it/s, early_stop_count=1, loss=0.08]\n",
      "NN Epoch 27 train   : 100%|██████████| 176/176 [00:02<00:00, 59.14it/s, early_stop_count=2, loss=0.05]\n",
      "NN Epoch 27 val     : 100%|██████████| 59/59 [00:00<00:00, 136.15it/s, early_stop_count=2, loss=0.08]\n",
      "NN Epoch 28 train   : 100%|██████████| 176/176 [00:02<00:00, 59.23it/s, early_stop_count=0, loss=0.05]\n",
      "NN Epoch 28 val     : 100%|██████████| 59/59 [00:00<00:00, 136.66it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 29 train   : 100%|██████████| 176/176 [00:02<00:00, 59.03it/s, early_stop_count=1, loss=0.04]\n",
      "NN Epoch 29 val     : 100%|██████████| 59/59 [00:00<00:00, 135.53it/s, early_stop_count=1, loss=0.08]\n",
      "NN Epoch 30 train   : 100%|██████████| 176/176 [00:02<00:00, 59.21it/s, early_stop_count=2, loss=0.04]\n",
      "NN Epoch 30 val     : 100%|██████████| 59/59 [00:00<00:00, 136.70it/s, early_stop_count=2, loss=0.07]\n",
      "NN Epoch 31 train   : 100%|██████████| 176/176 [00:02<00:00, 59.12it/s, early_stop_count=0, loss=0.04]\n",
      "NN Epoch 31 val     : 100%|██████████| 59/59 [00:00<00:00, 137.11it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 32 train   : 100%|██████████| 176/176 [00:02<00:00, 59.08it/s, early_stop_count=1, loss=0.04]\n",
      "NN Epoch 32 val     : 100%|██████████| 59/59 [00:00<00:00, 136.23it/s, early_stop_count=1, loss=0.08]\n",
      "NN Epoch 33 train   : 100%|██████████| 176/176 [00:02<00:00, 59.05it/s, early_stop_count=2, loss=0.04]\n",
      "NN Epoch 33 val     : 100%|██████████| 59/59 [00:00<00:00, 136.78it/s, early_stop_count=2, loss=0.07]\n",
      "NN Epoch 34 train   : 100%|██████████| 176/176 [00:02<00:00, 59.10it/s, early_stop_count=0, loss=0.04]\n",
      "NN Epoch 34 val     : 100%|██████████| 59/59 [00:00<00:00, 137.83it/s, early_stop_count=0, loss=0.08]\n",
      "NN Epoch 35 train   : 100%|██████████| 176/176 [00:03<00:00, 58.36it/s, early_stop_count=1, loss=0.04]\n",
      "NN Epoch 35 val     : 100%|██████████| 59/59 [00:00<00:00, 135.52it/s, early_stop_count=1, loss=0.07]\n",
      "NN Epoch 36 train   : 100%|██████████| 176/176 [00:03<00:00, 58.10it/s, early_stop_count=2, loss=0.04]\n",
      "NN Epoch 36 val     : 100%|██████████| 59/59 [00:00<00:00, 132.25it/s, early_stop_count=2, loss=0.09]\n",
      "NN Epoch 37 train   : 100%|██████████| 176/176 [00:03<00:00, 58.15it/s, early_stop_count=3, loss=0.04]\n",
      "NN Epoch 37 val     : 100%|██████████| 59/59 [00:00<00:00, 131.88it/s, early_stop_count=3, loss=0.08]\n",
      "NN Epoch 38 train   : 100%|██████████| 176/176 [00:03<00:00, 58.16it/s, early_stop_count=4, loss=0.04]\n",
      "NN Epoch 38 val     : 100%|██████████| 59/59 [00:00<00:00, 131.54it/s, early_stop_count=4, loss=0.07]\n"
     ]
    }
   ],
   "source": [
    "baseline_net = train(\n",
    "            device=device,\n",
    "            dataloaders=dataloaders,\n",
    "            dataset_sizes=dataset_sizes,\n",
    "            learning_rate=1.0e-4,\n",
    "            num_epochs=50,\n",
    "            early_stop_patience=5,\n",
    "            model_path=\"baseline_net.pth\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8196d86a-735f-4c5e-b6da-961b19ebe252",
   "metadata": {},
   "source": [
    "CVAE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dfb00ee-7612-4cef-ac1f-ab13a5bff2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Contributors to the Pyro project.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "# import os\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim, out_channel_1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=5, out_channels=out_channel_1, kernel_size=(30, 30))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(5, 5), stride=(5, 5))\n",
    "        \n",
    "        #in_features should be y.shape[1]\n",
    "        self.fc1 = nn.Linear(in_features=7840, out_features=100)\n",
    "        self.fc21 = nn.Linear(in_features=100, out_features=z_dim)\n",
    "        self.fc22 = nn.Linear(in_features=100, out_features=z_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # put x and y together in the same image for simplification\n",
    "        x = x.view(-1, 171, 171)\n",
    "        y = y.view(-1, 4)\n",
    "        y = y.unsqueeze(2)\n",
    "        #y.shape: (30,4,1)\n",
    "        y_0 = y[:,0,:].repeat(1,171).unsqueeze(2).repeat(1,1,171)\n",
    "        y_1 = y[:,1,:].repeat(1,171).unsqueeze(2).repeat(1,1,171)\n",
    "        y_2 = y[:,2,:].repeat(1,171).unsqueeze(2).repeat(1,1,171)\n",
    "        y_3 = y[:,3,:].repeat(1,171).unsqueeze(2).repeat(1,1,171)\n",
    "        yc = torch.stack((y_0, y_1, y_2, y_3), dim = 1)\n",
    "        xc = torch.cat((x.unsqueeze(1), yc),dim = 1)\n",
    "        \n",
    "        # then compute the hidden units\n",
    "        hidden = self.leakyrelu(self.conv(xc))\n",
    "        hidden = self.maxpool(hidden)\n",
    "        \n",
    "        hidden = torch.flatten(hidden, 1)\n",
    "        \n",
    "        hidden = self.leakyrelu(self.fc1(hidden))\n",
    "    \n",
    "        # then return a mean vector and a (positive) square root covariance\n",
    "        # each of size batch_size x z_dim\n",
    "        z_loc = self.fc21(hidden)\n",
    "        z_scale = torch.exp(self.fc22(hidden))\n",
    "        return z_loc, z_scale\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, 4)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, z):\n",
    "        y = self.leakyrelu(self.fc1(z))\n",
    "        y = self.fc2(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_1, pre_trained_baseline_net):\n",
    "        super().__init__()\n",
    "        # The CVAE is composed of multiple MLPs, such as recognition network\n",
    "        # qφ(z|x, y), (conditional) prior network pθ(z|x), and generation\n",
    "        # network pθ(y|x, z). Also, CVAE is built on top of the NN: not only\n",
    "        # the direct input x, but also the initial guess y_hat made by the NN\n",
    "        # are fed into the prior network.\n",
    "        self.baseline_net = pre_trained_baseline_net\n",
    "        self.prior_net = Encoder(z_dim, 10)\n",
    "        self.generation_net = Decoder(z_dim, hidden_1)\n",
    "        self.recognition_net = Encoder(z_dim, 10)\n",
    "\n",
    "    def model(self, xs, ys=None):\n",
    "        # register this pytorch module and all of its sub-modules with pyro\n",
    "        pyro.module(\"generation_net\", self)\n",
    "        batch_size = xs.shape[0]\n",
    "        with pyro.plate(\"data\"):\n",
    "\n",
    "            # Prior network uses the baseline predictions as initial guess.\n",
    "            # This is the generative process with recurrent connection\n",
    "            with torch.no_grad():\n",
    "                # this ensures the training process does not change the\n",
    "                # baseline network\n",
    "                y_hat = self.baseline_net(xs).view(-1,4)\n",
    "\n",
    "            # sample the handwriting style from the prior distribution, which is\n",
    "            # modulated by the input xs.\n",
    "            prior_loc, prior_scale = self.prior_net(xs, y_hat)\n",
    "            zs = pyro.sample(\"z\", dist.Normal(prior_loc, prior_scale).to_event(1))\n",
    "\n",
    "            # the output y is generated from the distribution pθ(y|x, z)\n",
    "            y_out = self.generation_net(zs)\n",
    "\n",
    "            if ys is not None:\n",
    "                # In training, we will only sample in the masked image\n",
    "                pyro.sample(\n",
    "                    \"y\",\n",
    "                    dist.Normal(y_out, 0.1, validate_args=False).to_event(1),\n",
    "                    obs=ys,\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                # In testing, no need to sample: the output is already a\n",
    "                # probability in [0, 1] range, which better represent pixel\n",
    "                # values considering grayscale. If we sample, we will force\n",
    "                # each pixel to be  either 0 or 1, killing the grayscale\n",
    "                pyro.deterministic(\"y\", y_out.detach())\n",
    "\n",
    "            # return the y_out so we can visualize it later\n",
    "            return y_out\n",
    "\n",
    "    def guide(self, xs, ys=None):\n",
    "        with pyro.plate(\"data\"):\n",
    "            if ys is None:\n",
    "                # at inference time, ys is not provided. In that case,\n",
    "                # the model uses the prior network\n",
    "                y_hat = self.baseline_net(xs).view(-1,4)\n",
    "                loc, scale = self.prior_net(xs, y_hat)\n",
    "            else:\n",
    "                # at training time, uses the variational distribution\n",
    "                # q(z|x,y) = normal(loc(x,y),scale(x,y))\n",
    "                loc, scale = self.recognition_net(xs, ys)\n",
    "\n",
    "            pyro.sample(\"z\", dist.Normal(loc, scale).to_event(1))\n",
    "\n",
    "\n",
    "def train(\n",
    "    device,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    learning_rate,\n",
    "    num_epochs,\n",
    "    early_stop_patience,\n",
    "    model_path,\n",
    "    pre_trained_baseline_net,\n",
    "):\n",
    "\n",
    "    # clear param store\n",
    "    pyro.clear_param_store()\n",
    "\n",
    "    cvae_net = CVAE(10, 100, pre_trained_baseline_net)\n",
    "    cvae_net.to(device)\n",
    "    optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "    svi = SVI(cvae_net.model, cvae_net.guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "\n",
    "    best_loss = np.inf\n",
    "    early_stop_count = 0\n",
    "    Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            running_loss = 0.0\n",
    "            num_preds = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            bar = tqdm(\n",
    "                dataloaders[phase],\n",
    "                desc=\"CVAE Epoch {} {}\".format(epoch, phase).ljust(20),\n",
    "            )\n",
    "            for i, batch in enumerate(bar):\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                outputs = batch[\"output\"].to(device)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss = svi.step(inputs, outputs)\n",
    "                else:\n",
    "                    loss = svi.evaluate_loss(inputs, outputs)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss / inputs.size(0)\n",
    "                num_preds += 1\n",
    "                if i % 10 == 0:\n",
    "                    bar.set_postfix(\n",
    "                        loss=\"{:.2f}\".format(running_loss / num_preds),\n",
    "                        early_stop_count=early_stop_count,\n",
    "                    )\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # deep copy the model\n",
    "            if phase == \"val\":\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    torch.save(cvae_net.state_dict(), model_path)\n",
    "                    early_stop_count = 0\n",
    "                else:\n",
    "                    early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= early_stop_patience:\n",
    "            break\n",
    "\n",
    "    # Save model weights\n",
    "    cvae_net.load_state_dict(torch.load(model_path))\n",
    "    cvae_net.eval()\n",
    "    return cvae_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ca88b3a-862c-4fa2-ac00-c64e84fca419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CVAE Epoch 0 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=7.51] \n",
      "CVAE Epoch 0 val    : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=0, loss=-0.49]\n",
      "CVAE Epoch 1 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-1.94]\n",
      "CVAE Epoch 1 val    : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=0, loss=0.24] \n",
      "CVAE Epoch 2 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=1, loss=-2.17]\n",
      "CVAE Epoch 2 val    : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=1, loss=-0.81]\n",
      "CVAE Epoch 3 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-2.30]\n",
      "CVAE Epoch 3 val    : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=0, loss=-0.81]\n",
      "CVAE Epoch 4 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-2.41]\n",
      "CVAE Epoch 4 val    : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=0, loss=-0.93]\n",
      "CVAE Epoch 5 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-2.56]\n",
      "CVAE Epoch 5 val    : 100%|██████████| 59/59 [00:08<00:00,  6.58it/s, early_stop_count=0, loss=-0.73]\n",
      "CVAE Epoch 6 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=1, loss=-2.60]\n",
      "CVAE Epoch 6 val    : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=1, loss=-0.94]\n",
      "CVAE Epoch 7 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-2.70]\n",
      "CVAE Epoch 7 val    : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=0, loss=-0.54]\n",
      "CVAE Epoch 8 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=1, loss=-2.76]\n",
      "CVAE Epoch 8 val    : 100%|██████████| 59/59 [00:08<00:00,  6.56it/s, early_stop_count=1, loss=-0.70]\n",
      "CVAE Epoch 9 train  : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=2, loss=-2.79]\n",
      "CVAE Epoch 9 val    : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=2, loss=-1.00]\n",
      "CVAE Epoch 10 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-2.84]\n",
      "CVAE Epoch 10 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=0, loss=-0.59]\n",
      "CVAE Epoch 11 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=1, loss=-2.89]\n",
      "CVAE Epoch 11 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=1, loss=-0.67]\n",
      "CVAE Epoch 12 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=2, loss=-2.92]\n",
      "CVAE Epoch 12 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=2, loss=-0.58]\n",
      "CVAE Epoch 13 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=3, loss=-2.98]\n",
      "CVAE Epoch 13 val   : 100%|██████████| 59/59 [00:08<00:00,  6.58it/s, early_stop_count=3, loss=-0.62]\n",
      "CVAE Epoch 14 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=4, loss=-2.96]\n",
      "CVAE Epoch 14 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=4, loss=-0.98]\n",
      "CVAE Epoch 15 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=5, loss=-3.03]\n",
      "CVAE Epoch 15 val   : 100%|██████████| 59/59 [00:08<00:00,  6.58it/s, early_stop_count=5, loss=-0.88]\n",
      "CVAE Epoch 16 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=6, loss=-3.00]\n",
      "CVAE Epoch 16 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=6, loss=-0.68]\n",
      "CVAE Epoch 17 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=7, loss=-3.10]\n",
      "CVAE Epoch 17 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=7, loss=-0.94]\n",
      "CVAE Epoch 18 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=8, loss=-3.08]\n",
      "CVAE Epoch 18 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=8, loss=-0.84]\n",
      "CVAE Epoch 19 train : 100%|██████████| 176/176 [00:40<00:00,  4.36it/s, early_stop_count=9, loss=-3.14]\n",
      "CVAE Epoch 19 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=9, loss=-1.18]\n",
      "CVAE Epoch 20 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=0, loss=-3.14]\n",
      "CVAE Epoch 20 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=0, loss=-0.75]\n",
      "CVAE Epoch 21 train : 100%|██████████| 176/176 [00:40<00:00,  4.36it/s, early_stop_count=1, loss=-3.18]\n",
      "CVAE Epoch 21 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=1, loss=-0.82]\n",
      "CVAE Epoch 22 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=2, loss=-3.20]\n",
      "CVAE Epoch 22 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=2, loss=-0.52]\n",
      "CVAE Epoch 23 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=3, loss=-3.21]\n",
      "CVAE Epoch 23 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=3, loss=-0.51]\n",
      "CVAE Epoch 24 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=4, loss=-3.19]\n",
      "CVAE Epoch 24 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=4, loss=-0.70]\n",
      "CVAE Epoch 25 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=5, loss=-3.23]\n",
      "CVAE Epoch 25 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=5, loss=-0.31]\n",
      "CVAE Epoch 26 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=6, loss=-3.25]\n",
      "CVAE Epoch 26 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=6, loss=-0.08]\n",
      "CVAE Epoch 27 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=7, loss=-3.28]\n",
      "CVAE Epoch 27 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=7, loss=-0.70]\n",
      "CVAE Epoch 28 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=8, loss=-3.32]\n",
      "CVAE Epoch 28 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=8, loss=-0.54]\n",
      "CVAE Epoch 29 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=9, loss=-3.29]\n",
      "CVAE Epoch 29 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=9, loss=-0.48]\n",
      "CVAE Epoch 30 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=10, loss=-3.31]\n",
      "CVAE Epoch 30 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=10, loss=-0.54]\n",
      "CVAE Epoch 31 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=11, loss=-3.38]\n",
      "CVAE Epoch 31 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=11, loss=-0.12]\n",
      "CVAE Epoch 32 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=12, loss=-3.36]\n",
      "CVAE Epoch 32 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=12, loss=-0.13]\n",
      "CVAE Epoch 33 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=13, loss=-3.41]\n",
      "CVAE Epoch 33 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=13, loss=0.04] \n",
      "CVAE Epoch 34 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=14, loss=-3.39]\n",
      "CVAE Epoch 34 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=14, loss=0.35]\n",
      "CVAE Epoch 35 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=15, loss=-3.38]\n",
      "CVAE Epoch 35 val   : 100%|██████████| 59/59 [00:08<00:00,  6.56it/s, early_stop_count=15, loss=-0.36]\n",
      "CVAE Epoch 36 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=16, loss=-3.40]\n",
      "CVAE Epoch 36 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=16, loss=0.05] \n",
      "CVAE Epoch 37 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=17, loss=-3.40]\n",
      "CVAE Epoch 37 val   : 100%|██████████| 59/59 [00:08<00:00,  6.60it/s, early_stop_count=17, loss=0.01] \n",
      "CVAE Epoch 38 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=18, loss=-3.36]\n",
      "CVAE Epoch 38 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=18, loss=-0.32]\n",
      "CVAE Epoch 39 train : 100%|██████████| 176/176 [00:40<00:00,  4.35it/s, early_stop_count=19, loss=-3.47]\n",
      "CVAE Epoch 39 val   : 100%|██████████| 59/59 [00:08<00:00,  6.59it/s, early_stop_count=19, loss=-0.00]\n"
     ]
    }
   ],
   "source": [
    "cvae_net = train(\n",
    "            device=device,\n",
    "            dataloaders=dataloaders,\n",
    "            dataset_sizes=dataset_sizes,\n",
    "            learning_rate=1.0e-4,\n",
    "            num_epochs=500,\n",
    "            early_stop_patience=20,\n",
    "            model_path=\"Gaucvae_net.pth\",\n",
    "            pre_trained_baseline_net=baseline_net,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e020918e-ef1b-4b0c-88d5-d5e2bb331666",
   "metadata": {},
   "source": [
    "PREDICT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b26d0b9d-a32c-4f6a-b72d-81ce701afdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed378e0-10e9-4a3a-935b-415d40d35f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_table(\n",
    "#     device,\n",
    "#     pre_trained_baseline,\n",
    "#     pre_trained_cvae,\n",
    "#     num_particles,\n",
    "#     col_name,\n",
    "# ):\n",
    "\n",
    "#     # Load sample random data\n",
    "#     datasets, dataloaders, dataset_sizes = get_data(batch_size=2)\n",
    "\n",
    "#     # Load sample data\n",
    "#     criterion = MSELoss()\n",
    "#     loss_fn = Trace_ELBO(num_particles=num_particles).differentiable_loss\n",
    "\n",
    "#     baseline_cll = 0.0\n",
    "#     cvae_mc_cll = 0.0\n",
    "#     num_preds = 0\n",
    "\n",
    "#     df = pd.DataFrame(index=[\"NN (baseline)\", \"CVAE (Monte Carlo)\"], columns=[col_name])\n",
    "\n",
    "#     # Iterate over data.\n",
    "#     bar = tqdm(dataloaders[\"val\"], desc=\"Generating predictions\".ljust(20))\n",
    "#     for batch in bar:\n",
    "#         inputs = batch[\"input\"].to(device)\n",
    "#         outputs = batch[\"output\"].to(device)\n",
    "#         num_preds += 1\n",
    "\n",
    "#         # Compute negative log likelihood for the baseline NN\n",
    "#         with torch.no_grad():\n",
    "#             preds = pre_trained_baseline(inputs)\n",
    "#         baseline_cll += criterion(preds, outputs).item() / inputs.size(0)\n",
    "\n",
    "#         # Compute the negative conditional log likelihood for the CVAE\n",
    "#         cvae_mc_cll += loss_fn(\n",
    "#             pre_trained_cvae.model, pre_trained_cvae.guide, inputs, outputs\n",
    "#         ).detach().item() / inputs.size(0)\n",
    "\n",
    "#     df.iloc[0, 0] = baseline_cll / num_preds\n",
    "#     df.iloc[1, 0] = cvae_mc_cll / num_preds\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d120579-9db5-4f47-bdf5-70ffa658fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = generate_table(\n",
    "#             device=device,\n",
    "#             pre_trained_baseline=baseline_net,\n",
    "#             pre_trained_cvae=cvae_net,\n",
    "#             num_particles=10,\n",
    "#             col_name=\"CLLs\",\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca95d4f9-1230-452b-80af-2c8928ab4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a217330-7ae2-4c90-b97a-b3196663f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets, dataloaders, dataset_sizes = get_data(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ce8968-18a9-41db-b994-d9686a339bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = dataset_sizes['test']\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d380c-0d87-42ea-945c-7c0fb3b4891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(datasets[\"test\"], batch_size=num_images, shuffle=False)\n",
    "\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "inputs = batch[\"input\"].to(device)\n",
    "outputs = batch[\"output\"].to(device)\n",
    "\n",
    "# Make predictions for baseline\n",
    "with torch.no_grad():\n",
    "    baseline_preds = baseline_net(inputs).view(outputs.shape)\n",
    "\n",
    "# Make predictions for cvae\n",
    "predictive = Predictive(\n",
    "    cvae_net.model, guide=cvae_net.guide, num_samples=num_samples\n",
    ")\n",
    "cvae_preds = predictive(inputs)[\"y\"].view(num_samples, num_images, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aac397-5b1a-45f0-8bf5-601855084074",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = outputs.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f17bc3-1502-4bff-aca1-ad73b6a96c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preds = baseline_preds.cpu().detach().numpy()\n",
    "cvae_preds = cvae_preds.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4274f-1da1-42b5-a21a-a39337d899f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('baseline_preds.npy', baseline_preds)\n",
    "np.save('Gaucvae_preds.npy', cvae_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6557640d-7202-4839-b665-a05369fb92c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "BASELINE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393db928-af1f-4ec3-a303-0f52dad0bd1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plotting:baseline\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    ax.scatter(y_test[:,i], baseline_preds[:,i], s=1.0)\n",
    "    ax.set_xlabel('y_true')\n",
    "    ax.set_ylabel('y_pred')\n",
    "    ax.axline([0, 0], [1, 1], linestyle='dotted', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c9c44-257c-4198-b35c-e83e5c2f1026",
   "metadata": {},
   "source": [
    "CVAE PREDICTION WITHOUT CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a28c6-ace8-40e7-a0a4-db83f61103de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting:cvae\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    mean = np.mean(cvae_preds[:,:,i], axis=0)\n",
    "    \n",
    "    ax.scatter(y_test[:,i], mean, s=1.0)\n",
    "    ax.set_xlabel('y_true')\n",
    "    ax.set_ylabel('y_pred')\n",
    "    ax.axline([0, 0], [1, 1], linestyle='dotted', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52393a6c-7975-4a78-a641-9bffcd169db9",
   "metadata": {},
   "source": [
    "CVAE PREDICTION WITH CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b292dfc-e8e8-4d81-804b-b5f047fa2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting:cvae\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    mean = np.mean(cvae_preds[:,:,i], axis=0)\n",
    "    std = np.std(cvae_preds[:,:,i], axis=0)\n",
    "    ci = 1.96 * std\n",
    "    \n",
    "    ax.errorbar(y_test[:,i], mean, yerr=ci, fmt='o', markersize=3.0, linewidth=1.0)\n",
    "    ax.set_xlabel('y_true')\n",
    "    ax.set_ylabel('y_pred')\n",
    "    ax.axline([0, 0], [1, 1], linestyle='dotted', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4490b-c80a-44f8-b41c-7a7bc9d31fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch [pytorch]",
   "language": "python",
   "name": "conda_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
